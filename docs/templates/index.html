<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Expansion</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Arimo&family=Varela+Round&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Literata&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="index.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="./assets/js/index.js"></script>
</head>

<body>
  <header class="page-header">
    <h1 class="">Melody Infilling with User-Provided Structural Context</h1>
    <!-- <h2 class=""></h2> -->
    <a class="page-header__link" target='_blank' href="{{repo}}">
      Github</a>
    <a class="page-header__link" target='_blank' href="{{arxiv}}">
      Paper</a>
  </header>

  <main>
    <div id="content-div">
    <section id="inpainted-music">
      <p>
      <div>
        This is the demo page for ISMIR 2022 paper: Melody Infilling with User-Provided Structural Context. <br>
        Authors: Chih-Pin Tan, Wen-Yu Su and Yi-Hsuan Yang
      </div>
      </p>

      <h2> Demo 1 </h2>

      <p>
      Demo 1 contains 3 sets of infilling results generated by our model, VLI, and Hsu's work. Besides, We provide the original music with "Real" tag, and the result of "copying the provide structural cotext" with "Copy" tag. <br>
      In the pianoroll player, the orange notes belong to the past and future context, and the purple notes in the middle belong to the infilling result. <br>
      As mentioned in the paper, we notice our model generates results much similar to the provided structural context (over imitation).
      However, with our subjective listening, our model still performs better than "Copy" on connecting the targets to the contexts, particularly "to the past context".
      </p>

      {% for i in range(len(demo1)) %}

      {% include "midi_player.html" with song_idx=demo1[i] models=models1 title=(i+1) ID=(i+1)%}

      {% endfor %}

      <h2> Demo 2 </h2>
      <p>
      While preparing for the demo, we found a good strategy to remedy the problem of over-imitating.
      Instead of considering only the loss of predicting the infilling target as described in our paper, we trained an "improved" model that considers the loss of not only the infilling target but also the past context while training.
      We found doing so much reduces the imitation problem. <br>

      In Demo 2, we provide the results of the improved model with 'Improved' tag.
      Please note that this is unpublished result not mentioned in the paper at all.
      (The model evaluated either objective or subjective remains to be the one demonstrated in Demo 1.)
      </p>

      {% for i in range(len(demo1)) %}

      {% include "midi_player.html" with song_idx=demo1[i] models=models2 title=(i+1) ID=(i+4)%}

      {% endfor %}

      <p>Note: If you are browsing this page using an iPhone, please remember to turn the silent mode off through the
        switch on the side of your iPhone.</p>

    </section>
    </div>

    <footer class="site-footer">
      <span class="site-footer-credit">We use
        <a target='_blank' href='https://github.com/cifkao/html-midi-player'>html_midi_player</a>
        built and kindly shared publicly by
        <a target='_blank' href="https://ondrej.cifka.com">Ondřej Cífka</a>
        for visualizing the piano rolls of the MIDI files. We have also made this implementation
        of the website public at the <a target='_blank'
          href="{{repo}}">Github repository</a>.
      </span>
    </footer>
  </main>
  <script
    src="https://cdn.jsdelivr.net/combine/npm/tone@14.7.58,npm/@magenta/music@1.21.0/es6/core.js,npm/focus-visible@5,npm/html-midi-player@1.1.0"></script>

</body>

</html>